{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9083e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d98cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mykey= openai.api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "460405b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28eb1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "myllm = OpenAI(\n",
    "    model= ('text-davinci-003'),\n",
    "    temperature=1,\n",
    "    openai_api_key= mykey\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "126d9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = myllm.generate(\n",
    "    prompts=[\"what year it is?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac86b07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nIt is 2020.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 11, 'completion_tokens': 6, 'prompt_tokens': 5}, 'model_name': 'text-davinci-003'}, run=[RunInfo(run_id=UUID('d19f404d-f53b-4665-abe6-561ce20bf0b5'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bf32752",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = myllm.generate(\n",
    "    prompts=[\"tell me top 2 {n} in india. n=sports\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b368384b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\n1. Cricket\\n2. Football', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 23, 'completion_tokens': 9, 'prompt_tokens': 14}, 'model_name': 'text-davinci-003'}, run=[RunInfo(run_id=UUID('cbbff15b-5f93-4e12-9067-ba44688419aa'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8f28cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Mumbai \n",
      "2. Delhi\n"
     ]
    }
   ],
   "source": [
    "print( myllm(prompt=\"tell me 2 best {item} in India.item=city\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fa9eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lwsum(i):\n",
    "    x=i\n",
    "    y=10\n",
    "    z=x+y\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50779f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lwsum(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f799f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1007f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lwprompt=PromptTemplate(\n",
    "    template=\"tell me 2 best {i} in {c}. \",\n",
    "    input_variables=[\"i\",\"c\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17e89fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell me 2 best food in canada. '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lwprompt.format(i=\"food\",c=\"canada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66e45e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Honda Civic \\n2. Toyota Corolla'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myllm(prompt=lwprompt.format(i=\"car\",c=\"canada\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d37af326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac8e0585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1) Fufu & Stew (Ghana) \n",
      "2) Biltong (South Africa)\n"
     ]
    }
   ],
   "source": [
    "mychain = LLMChain(\n",
    "  llm=myllm,\n",
    "  prompt=lwprompt\n",
    "  )\n",
    "print(mychain.run(i=\"food\",c=\"africa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cfb23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bef9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec6f277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SERPAPI_API_KEY'] = myserpkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f2ac4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "myserpkey=\"9d473fb7abff2bc40d8adf86587fe2c6249072aaff3e4f62acd107dedf7192ee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de01d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "babc5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "myserptool=load_tools(tool_names=[\"serpapi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ce2a2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='9d473fb7abff2bc40d8adf86587fe2c6249072aaff3e4f62acd107dedf7192ee', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='9d473fb7abff2bc40d8adf86587fe2c6249072aaff3e4f62acd107dedf7192ee', aiosession=None)>)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myserptool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39407af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96f3f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5c7a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mygooglechain=initialize_agent(\n",
    "    llm=myllm,\n",
    "    tools=myserptool,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4061a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to figure out what steps to take to integrate the model\n",
      "Action: Search\n",
      "Action Input: openai llm model Twitter integration\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mToday, we're going to be creating an AI Tweet Generator using LangChain and OpenAI's LLMs. It's a simple project that takes in a Tweet topic ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the actual steps for integrating\n",
      "Action: Search\n",
      "Action Input: openai llm model Twitter integration steps\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA step-by-step guide demonstrating how to create a twitter bot based on python using Streamlit and GPT-3 to generate twitter posts and posting them.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the steps for integrating\n",
      "Final Answer: The procedure to integrate OpenAI LLM model with Twitter involves creating a twitter bot using Streamlit and GPT-3, and then using this bot to generate tweets and post them.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The procedure to integrate OpenAI LLM model with Twitter involves creating a twitter bot using Streamlit and GPT-3, and then using this bot to generate tweets and post them.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mygooglechain.run(\"what are the \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa1962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
